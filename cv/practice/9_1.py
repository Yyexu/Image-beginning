import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
import numpy as np

# ---------------------- 1. é…ç½®åŸºç¡€å‚æ•°ï¼ˆå’Œè®­ç»ƒæ—¶ä¸€è‡´ï¼‰ ----------------------
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
NUM_CLASSES = 10  # CIFAR-10å…±10ä¸ªç±»åˆ«
# ç±»åˆ«åç§°ï¼ˆå’Œè®­ç»ƒæ—¶ä¸€è‡´ï¼‰
classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',
           'dog', 'frog', 'horse', 'ship', 'truck')


# ---------------------- 2. å®šä¹‰å’Œè®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´çš„æ¨¡å‹ç»“æ„ ----------------------
# æ³¨æ„ï¼šå¿…é¡»å’Œè®­ç»ƒä»£ç é‡Œçš„SimpleCNNå®Œå…¨ä¸€æ ·ï¼ˆæ”¹ä¸€ä¸ªå±‚éƒ½åŠ è½½å¤±è´¥ï¼‰
class SimpleCNN(nn.Module):
    def __init__(self, num_classes=10):
        super(SimpleCNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128 * 4 * 4, 512),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(512, num_classes),
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x


# ---------------------- 3. åŠ è½½æ¨¡å‹æƒé‡ï¼ˆå…³é”®æ­¥éª¤ï¼‰ ----------------------
# åˆå§‹åŒ–æ¨¡å‹
model = SimpleCNN(num_classes=NUM_CLASSES).to(DEVICE)
# åŠ è½½.pthæƒé‡æ–‡ä»¶ï¼ˆæ›¿æ¢ä¸ºä½ çš„æ¨¡å‹è·¯å¾„ï¼Œæ¯”å¦‚'cifar10_cnn.pth'ï¼‰
model_path = "cifar10_cnn.pth"
# åŠ è½½æƒé‡ï¼ˆmap_locationç¡®ä¿CPU/GPUéƒ½èƒ½åŠ è½½ï¼‰
model.load_state_dict(torch.load(model_path, map_location=DEVICE))
# åˆ‡æ¢åˆ°æ¨ç†æ¨¡å¼ï¼ˆç¦ç”¨Dropout/BatchNormï¼Œé¿å…ç»“æœä¸å‡†ï¼‰
model.eval()
print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œå·²è¿›å…¥æ¨ç†æ¨¡å¼")

# ---------------------- 4. å®šä¹‰å›¾åƒé¢„å¤„ç†ï¼ˆå’Œè®­ç»ƒæ—¶çš„test_transformä¸€è‡´ï¼‰ ----------------------
transform = transforms.Compose([
    transforms.Resize((32, 32)),  # CIFAR-10æ˜¯32x32ï¼Œå¿…é¡»ç¼©æ”¾åˆ°ä¸€è‡´å°ºå¯¸
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.4914, 0.4822, 0.4465],
        std=[0.2023, 0.1994, 0.2010]
    )
])


# ---------------------- 5. æ¨ç†å•å¼ å›¾åƒï¼ˆæ ¸å¿ƒï¼šé¢„æµ‹ç±»åˆ«ï¼‰ ----------------------
def predict_image(image_path):
    # 1. åŠ è½½å›¾åƒï¼ˆæ”¯æŒjpg/pngç­‰æ ¼å¼ï¼‰
    img = Image.open(image_path).convert('RGB')  # è½¬ä¸ºRGBï¼ˆé¿å…ç°åº¦å›¾/é€æ˜é€šé“é—®é¢˜ï¼‰
    # 2. é¢„å¤„ç†
    img_tensor = transform(img).unsqueeze(0)  # å¢åŠ batchç»´åº¦ï¼ˆæ¨¡å‹è¦æ±‚è¾“å…¥æ˜¯[batch, C, H, W]ï¼‰
    img_tensor = img_tensor.to(DEVICE)
    # 3. æ¨¡å‹æ¨ç†ï¼ˆç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒåŠ é€Ÿ+çœå†…å­˜ï¼‰
    with torch.no_grad():
        outputs = model(img_tensor)  # è¾“å‡ºï¼š[1, 10]ï¼ˆæ¯ä¸ªç±»åˆ«çš„å¾—åˆ†ï¼‰
        # 4. è§£æç»“æœï¼šå–å¾—åˆ†æœ€é«˜çš„ç±»åˆ«
        _, predicted_idx = torch.max(outputs, 1)  # å¾—åˆ°ç±»åˆ«ç´¢å¼•
        predicted_class = classes[predicted_idx.item()]  # è½¬ä¸ºç±»åˆ«åç§°
        # å¯é€‰ï¼šè¾“å‡ºæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡ï¼ˆSoftmaxè½¬æ¢ï¼‰
        probabilities = torch.softmax(outputs, dim=1).squeeze().cpu().numpy()
        class_prob = {classes[i]: round(probabilities[i] * 100, 2) for i in range(NUM_CLASSES)}

    # 5. è¿”å›ç»“æœ
    print(f"ğŸ“Œ é¢„æµ‹ç»“æœï¼š{predicted_class}")
    print(f"ğŸ“Š å„ç±»åˆ«æ¦‚ç‡ï¼š{class_prob}")
    return predicted_class


# ---------------------- 6. è¿è¡Œæ¨ç†ï¼ˆæ›¿æ¢ä¸ºä½ çš„æµ‹è¯•å›¾åƒè·¯å¾„ï¼‰ ----------------------
if __name__ == "__main__":
    # æ›¿æ¢ä¸ºä½ çš„å›¾åƒè·¯å¾„ï¼ˆæ¯”å¦‚CIFAR-10çš„æµ‹è¯•å›¾ã€è‡ªå·±æ‹çš„å›¾ï¼‰
    test_image_path = "çŒ«.jpg"
    predict_image(test_image_path)